{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_1/'):\n",
    "    if (file!='dados.log' and file!='notas_finais.log' and (file=='54db0c6a27541070e9415a3d.csv' or file=='54db0c6a27541070e9415a3e.csv' or file=='54dbb8cc27541070e9415a41.csv')):\n",
    "        dfs.append(pd.read_csv('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_1/'+file))\n",
    "for file in os.listdir('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_2/'):\n",
    "    if (file!='dados.log' and file!='notas_finais.log' and (file=='54db0c6a27541070e9415a3d.csv' or file=='54db0c6a27541070e9415a3e.csv' or file=='54dbb8cc27541070e9415a41.csv')):\n",
    "        dfs.append(pd.read_csv('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_2/'+file))\n",
    "for file in os.listdir('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_3/'):\n",
    "     if (file!='dados.log' and file!='notas_finais.log' and (file=='54db0c6a27541070e9415a3d.csv' or file=='54db0c6a27541070e9415a3e.csv' or file=='54dbb8cc27541070e9415a41.csv')):\n",
    "        dfs.append(pd.read_csv('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_3/'+file))\n",
    "for file in os.listdir('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_4/'):\n",
    "     if (file!='dados.log' and file!='notas_finais.log' and (file=='54db0c6a27541070e9415a3d.csv' or file=='54db0c6a27541070e9415a3e.csv' or file=='54dbb8cc27541070e9415a41.csv')):\n",
    "        dfs.append(pd.read_csv('/home/samuel/Documentos/antigo/estey_coady/por_média/semestre_4/'+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(dfs)\n",
    "df=df.groupby('Id_aluno', as_index=False).mean()\n",
    "#df['final_exam']=dfs[0]['final_exam']\n",
    "#df=pd.read_csv('/home/samuel/estey_coady/por_média/semestre_3/54db0c6a27541070e9415a3d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(df):\n",
    "    from sklearn import preprocessing\n",
    "    np_scaled = preprocessing.scale(df)\n",
    "    df_normalized = pd.DataFrame(np_scaled, columns = df.columns)\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizacao_das_medias(df):\n",
    "    df.loc[df.final_exam<50.0, 'final_exam'] = 0\n",
    "    df.loc[df.final_exam>=50.0, 'final_exam'] = 1\n",
    "    df['final_exam'] = df.final_exam.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subamostragem_balanceamento(df):\n",
    "    g = df.groupby('final_exam')\n",
    "    df = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compiles</th>\n",
       "      <th>correct_attempts</th>\n",
       "      <th>error</th>\n",
       "      <th>hints</th>\n",
       "      <th>runs</th>\n",
       "      <th>total_attempts</th>\n",
       "      <th>time</th>\n",
       "      <th>final_exam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123451</td>\n",
       "      <td>-0.171905</td>\n",
       "      <td>-0.381206</td>\n",
       "      <td>-0.187535</td>\n",
       "      <td>-0.130001</td>\n",
       "      <td>-0.163563</td>\n",
       "      <td>-0.400679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.123451</td>\n",
       "      <td>-0.171905</td>\n",
       "      <td>-0.381206</td>\n",
       "      <td>-0.187535</td>\n",
       "      <td>-0.130001</td>\n",
       "      <td>-0.163563</td>\n",
       "      <td>-0.400679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.123451</td>\n",
       "      <td>-0.171905</td>\n",
       "      <td>-0.381206</td>\n",
       "      <td>-0.187535</td>\n",
       "      <td>-0.130001</td>\n",
       "      <td>-0.163563</td>\n",
       "      <td>-0.400679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.123451</td>\n",
       "      <td>-0.171905</td>\n",
       "      <td>-0.381206</td>\n",
       "      <td>-0.187535</td>\n",
       "      <td>-0.130001</td>\n",
       "      <td>-0.163563</td>\n",
       "      <td>-0.400679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040883</td>\n",
       "      <td>-0.024998</td>\n",
       "      <td>-0.312122</td>\n",
       "      <td>9.193197</td>\n",
       "      <td>-0.026199</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>3.533405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compiles  correct_attempts     error     hints      runs  total_attempts  \\\n",
       "0 -0.123451         -0.171905 -0.381206 -0.187535 -0.130001       -0.163563   \n",
       "1 -0.123451         -0.171905 -0.381206 -0.187535 -0.130001       -0.163563   \n",
       "2 -0.123451         -0.171905 -0.381206 -0.187535 -0.130001       -0.163563   \n",
       "3 -0.123451         -0.171905 -0.381206 -0.187535 -0.130001       -0.163563   \n",
       "4 -0.040883         -0.024998 -0.312122  9.193197 -0.026199       -0.004411   \n",
       "\n",
       "       time  final_exam  \n",
       "0 -0.400679           0  \n",
       "1 -0.400679           0  \n",
       "2 -0.400679           0  \n",
       "3 -0.400679           0  \n",
       "4  3.533405           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas = ['Id_aluno']\n",
    "df= df.drop(labels = colunas, axis=1)\n",
    "df.loc[:, df.columns != 'final_exam'] = normalizacao(df.loc[:, df.columns != 'final_exam'])\n",
    "df = discretizacao_das_medias(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('final_exam', axis=1).values, df['final_exam'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from numpy import loadtxt\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# params = {  \n",
    "#       'nthread':[4,5,6], #when use hyperthread, xgboost may become slower\n",
    "#       'objective':['binary:logistic'],\n",
    "#       'learning_rate': [0.05,0.06,0.07], #so called `eta` value\n",
    "#       'max_depth': [5,6,7,8,9],\n",
    "#       'min_child_weight': [9,10,11,12,13],\n",
    "#       'silent': [1,2,3],\n",
    "#       'subsample': [0.8,0.9],\n",
    "#       'colsample_bytree': [0.7,0.8,0.9],\n",
    "#       'n_estimators': [4,5,6], #number of trees, change it to 1000 for better results\n",
    "#       'missing':[-999],\n",
    "#       'seed': [1337],\n",
    "#       'early_stopping':[True],\n",
    "# }\n",
    "\n",
    "# knn = XGBClassifier()\n",
    "# grid = RandomizedSearchCV(knn, params, cv=10, n_jobs=-1, verbose=1, n_iter=10) #n_jobs = -1 faz a computação em paralelo\n",
    "# grid.fit(X,y)\n",
    "\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_estimator_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1747 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 5247 tasks      | elapsed:   14.0s\n"
     ]
    }
   ],
   "source": [
    "params1 = {  \n",
    "    \"bootstrap\":[True],\n",
    "    \"criterion\":['entropy','gini'], \n",
    "    \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "    \"min_samples_leaf\":[5,6,7,8,9], \n",
    "    \"min_samples_split\":[16,17,18,19,20,21],\n",
    "    \"max_depth\" : [4,5,6,7,8],\n",
    "    \"class_weight\":['balanced','balanced_subsample'],\n",
    "}\n",
    "\n",
    "knn1 = ExtraTreesClassifier()\n",
    "grid1 = RandomizedSearchCV(knn1, params1, cv=10, n_jobs=-1, verbose=1, n_iter=1000) #n_jobs = -1 faz a computação em paralelo\n",
    "grid1.fit(X,y)\n",
    "\n",
    "print(grid1.best_params_)\n",
    "print(grid1.best_estimator_)\n",
    "print(grid1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {  \n",
    "    \"bootstrap\":[True],\n",
    "    \"criterion\":['entropy','gini'], \n",
    "    \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "    \"min_samples_leaf\":[5,6,7,8,9], \n",
    "    \"min_samples_split\":[16,17,18,19,20,21],\n",
    "    \"max_depth\" : [4,5,6,7,8],\n",
    "    \"class_weight\":['balanced','balanced_subsample'],\n",
    "}\n",
    "knn2 = RandomForestClassifier()\n",
    "grid2 = RandomizedSearchCV(knn2, params2, cv=10, n_jobs=-1, verbose=1, n_iter=1000) #n_jobs = -1 faz a computação em paralelo\n",
    "grid2.fit(X,y)\n",
    "\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_estimator_)\n",
    "print(grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_digits as load_data\n",
    "import scikitplot as skplt\n",
    "\n",
    "\n",
    "X, y = df.drop('final_exam', axis=1).values, df['final_exam'].values\n",
    "nb = GaussianNB()\n",
    "nb.fit(X, y)\n",
    "probas = nb.predict_proba(X)\n",
    "skplt.metrics.plot_roc(y_true=y, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "#pipeline = make_pipeline(\n",
    "#            RFE(estimator=ExtraTreesClassifier(criterion=\"gini\", n_estimators=100), step=0.5),\n",
    "#            RandomForestClassifier(max_features=0.9500000000000001, min_samples_leaf=20, n_estimators=500)\n",
    "#        )\n",
    "\n",
    "#pipeline = RandomForestClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.45, min_samples_leaf=7, min_samples_split=19,class_weight='balanced_subsample')\n",
    "pipeline =grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score = cross_val_score(pipeline, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#clf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X,y,cv=10)\n",
    "print(confusion_matrix(y,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#df = pd.DataFrame(X)\n",
    "#df['target'] = y\n",
    "cont_target = df.final_exam.value_counts()\n",
    "cont_target.plot(kind='bar', color=['blue', 'red'], title='Distribuição das notas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "a = pca.fit_transform(X)\n",
    "\n",
    "plot_2d_space(a, y, 'Base de dados desbalanceada (2 PCA components)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, id_rus = rus.fit_sample(X, y)\n",
    "\n",
    "print('Índices removidos:', id_rus)\n",
    "\n",
    "plot_2d_space(X_rus, y_rus, 'Random Undersampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_rus, y_rus)\n",
    "probas = nb.predict_proba(X_rus)\n",
    "skplt.metrics.plot_roc(y_true=y_rus, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score = cross_val_score(pipeline, X_rus, y_rus, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#clf1=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_rus,y_rus,cv=10)\n",
    "print(confusion_matrix(y_rus,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_rus,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X, y)\n",
    "\n",
    "print(X_ros.shape[0] - X.shape[0], 'new random picked points')\n",
    "print(X_ros.shape[0] - X.shape[0], 'novos pontos aleatórios selecionados')\n",
    "\n",
    "plot_2d_space(X_ros, y_ros, 'Random Oversampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_ros, y_ros)\n",
    "probas = nb.predict_proba(X_ros)\n",
    "skplt.metrics.plot_roc(y_true=y_ros, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(pipeline, X_ros, y_ros, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_ros,y_ros,cv=10)\n",
    "print(confusion_matrix(y_ros,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_ros,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(return_indices=True, sampling_strategy='majority')\n",
    "X_tl, y_tl, id_tl = tl.fit_sample(X, y)\n",
    "\n",
    "print('Removed indexes:', id_tl)\n",
    "\n",
    "plot_2d_space(X_tl, y_tl, 'Tomek links under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_tl, y_tl)\n",
    "probas = nb.predict_proba(X_tl)\n",
    "skplt.metrics.plot_roc(y_true=y_tl, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(pipeline, X_tl, y_tl, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_tl,y_tl,cv=10)\n",
    "print(confusion_matrix(y_tl,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_tl,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids()\n",
    "X_cc, y_cc = cc.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_cc, y_cc, 'Cluster Centroids Undersampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont=0\n",
    "a=[]\n",
    "while(cont<len(X_cc)):\n",
    "    flag=1\n",
    "    for cada in X_cc[cont]:\n",
    "        if cada!=0:\n",
    "            flag=0\n",
    "    if flag==0:\n",
    "        a+=[[X_cc[cont][0]]+[X_cc[cont][1]]+[X_cc[cont][2]]+[X_cc[cont][3]]+[X_cc[cont][4]]+[X_cc[cont][5]]+[X_cc[cont][6]]+[y_cc[cont]]]\n",
    "    cont+=1\n",
    "#a=np.array(a)\n",
    "#a[0]\n",
    "\n",
    "pd.DataFrame(a).to_csv(\"help.csv\")\n",
    "df=pd.read_csv('help.csv')\n",
    "df=df.drop(df.columns[[0]], axis=1)\n",
    "df['final_exam']=df['7']\n",
    "df=df.drop(df.columns[[-2]], axis=1)\n",
    "X_cc, y_cc = df.drop('final_exam', axis=1).values, df['final_exam'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_cc, y_cc)\n",
    "probas = nb.predict_proba(X_cc)\n",
    "skplt.metrics.plot_roc(y_true=y_cc, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(pipeline, X_cc, y_cc, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#clf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_cc,y_cc,cv=10)\n",
    "print(confusion_matrix(y_cc,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_cc,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', k_neighbors=5)\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_sm, y_sm, 'SMOTE over-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_sm, y_sm)\n",
    "probas = nb.predict_proba(X_sm)\n",
    "skplt.metrics.plot_roc(y_true=y_sm, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(pipeline, X_sm, y_sm, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_sm,y_sm,cv=10)\n",
    "print(confusion_matrix(y_sm,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_sm,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', k_neighbors=3)\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_sm, y_sm, 'SMOTE over-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_sm, y_sm)\n",
    "probas = nb.predict_proba(X_sm)\n",
    "skplt.metrics.plot_roc(y_true=y_sm, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(pipeline, X_sm, y_sm, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_sm,y_sm,cv=10)\n",
    "print(confusion_matrix(y_sm,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_sm,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='auto')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_smt, y_smt, 'SMOTE + Tomek links')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_smt, y_smt)\n",
    "probas = nb.predict_proba(X_smt)\n",
    "skplt.metrics.plot_roc(y_true=y_smt, y_probas=probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(pipeline, X_smt, y_smt, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred=cross_val_predict(pipeline,X_smt,y_smt,cv=10)\n",
    "print(confusion_matrix(y_smt,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_smt,y_pred))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=[]#[['compiles','correct_attempts','error','hints','runs','total_attempts','time','final_exam']]\n",
    "cont=0\n",
    "a=[]\n",
    "X_ros=X_cc\n",
    "y_ros=y_cc\n",
    "# X_cc=X\n",
    "# y_cc=y\n",
    "while(cont<len(X_ros)):\n",
    "    flag=1\n",
    "    for cada in X_ros[cont]:\n",
    "        if cada!=0:\n",
    "            flag=0\n",
    "    if flag==0:\n",
    "        a+=[[X_ros[cont][0]]+[X_ros[cont][1]]+[X_ros[cont][2]]+[X_ros[cont][3]]+[X_ros[cont][4]]+[X_ros[cont][5]]+[X_ros[cont][6]]+[y_ros[cont]]]\n",
    "    cont+=1\n",
    "# while(cont<len(X_cc)):\n",
    "   \n",
    "#         a+=[[X_cc[cont][0]]+[X_cc[cont][1]]+[X_cc[cont][2]]+[X_cc[cont][3]]+[X_cc[cont][4]]+[X_cc[cont][5]]+[X_cc[cont][6]]+[y_cc[cont]]]\n",
    "#         cont+=1\n",
    "#a=np.array(a)\n",
    "#a[0]\n",
    "\n",
    "pd.DataFrame(a).to_csv(\"help.csv\")\n",
    "df=pd.read_csv('help.csv')\n",
    "df=df.drop(df.columns[[0]], axis=1)\n",
    "df['final_exam']=df['7']\n",
    "df=df.drop(df.columns[[-2]], axis=1)\n",
    "# df.loc[:, df.columns != 'final_exam'] = normalizacao(df.loc[:, df.columns != 'final_exam'])\n",
    "housing = df.drop(\"final_exam\", axis=1)\n",
    "housing_labels = df[\"final_exam\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "\n",
    "def cross_val(estimator,X, y):\n",
    "    scores = cross_val_score(estimator, X, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    return np.sqrt(-scores)\n",
    "\n",
    "tree_rmse_scores = cross_val(tree_reg, housing, housing_labels)\n",
    "\n",
    "lin_reg_scores = cross_val(lin_reg, housing, housing_labels)\n",
    "\n",
    "forest_reg_rmse_scores = cross_val(forest_reg, housing, housing_labels)\n",
    "def display_scores(scores, alg_name):\n",
    "    print(alg_name)\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print('---------------------------------')\n",
    "\n",
    "display_scores(tree_rmse_scores, 'DecisionTreeRegressor')\n",
    "display_scores(lin_reg_scores, 'LinearRegression')\n",
    "display_scores(forest_reg_rmse_scores, 'RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(housing, housing_labels)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_pos=np.array([1, 7, 12, 14,16,20,24])\n",
    "print(x_pos)\n",
    "bar_1=feature_importances[0]\n",
    "bar_2=feature_importances[1]\n",
    "bar_3=feature_importances[2]\n",
    "bar_4=feature_importances[3]\n",
    "bar_5=feature_importances[4]\n",
    "bar_6=feature_importances[5]\n",
    "bar_7=feature_importances[6]\n",
    "plt.bar([1], bar_1)\n",
    "plt.bar([7], bar_2)\n",
    "plt.bar([12], bar_3)\n",
    "plt.bar([14], bar_4)\n",
    "plt.bar([16], bar_5)\n",
    "plt.bar([20], bar_6)\n",
    "plt.bar([24], bar_7)\n",
    "\n",
    "plt.xticks(x_pos+0.25,('compiles','correct_attempts','error','hints','runs','total_attempts','time'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(['compiles', 'correct_attempts', 'error_free_compiles', 'hints', 'runs', 'total_attempts','time'])\n",
    "cont=0\n",
    "passou=0\n",
    "npassou=0\n",
    "stats1=[0,0,0,0,0,0,0]\n",
    "stats2=[0,0,0,0,0,0,0]\n",
    "for elemento in housing_labels:\n",
    "    if elemento==0:\n",
    "        stats1[0]+=housing.loc[cont,['0']].values[0]\n",
    "        stats1[1]+=housing.loc[cont,['1']].values[0]\n",
    "        stats1[2]+=housing.loc[cont,['2']].values[0]\n",
    "        stats1[3]+=housing.loc[cont,['3']].values[0] \n",
    "        stats1[4]+=housing.loc[cont,['4']].values[0]\n",
    "        stats1[5]+=housing.loc[cont,['5']].values[0]\n",
    "        stats1[6]+=housing.loc[cont,['6']].values[0]\n",
    "        npassou+=1\n",
    "    else:\n",
    "        stats2[0]+=housing.loc[cont,['0']].values[0]\n",
    "        stats2[1]+=housing.loc[cont,['1']].values[0]\n",
    "        stats2[2]+=housing.loc[cont,['2']].values[0]\n",
    "        stats2[3]+=housing.loc[cont,['3']].values[0] \n",
    "        stats2[4]+=housing.loc[cont,['4']].values[0]\n",
    "        stats2[5]+=housing.loc[cont,['5']].values[0]\n",
    "        stats2[6]+=housing.loc[cont,['6']].values[0]\n",
    "        passou+=1\n",
    "    cont+=1\n",
    "            \n",
    "cont=0\n",
    "while(cont<len(stats1)):\n",
    "    stats1[cont]=stats1[cont]/npassou\n",
    "    cont+=1\n",
    "cont=0\n",
    "while(cont<len(stats2)):\n",
    "    stats2[cont]=stats2[cont]/passou\n",
    "    cont+=1\n",
    "stats1=np.asarray(stats1)\n",
    "stats2=np.asarray(stats2)\n",
    "print(stats1)\n",
    "print(stats2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles=np.linspace(0, 2*np.pi, len(labels), endpoint=False)\n",
    "# close the plot\n",
    "stats1=np.concatenate((stats1,[stats1[0]]))\n",
    "angles=np.concatenate((angles,[angles[0]]))\n",
    "stats2=np.concatenate((stats2,[stats2[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111, polar=True)\n",
    "ax.plot(angles, stats1, 'o-', linewidth=2,color='red')\n",
    "ax.fill(angles, stats1, alpha=0.25,color='red')\n",
    "ax.set_thetagrids(angles * 180/np.pi, labels,color='black')\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "bx = plt.subplot(111, polar=True)\n",
    "bx.plot(angles, stats2, 'o-', linewidth=2,color='green')\n",
    "bx.fill(angles, stats2, alpha=0.25,color='green')\n",
    "bx.set_thetagrids(angles * 180/np.pi, labels)\n",
    "bx.grid(True)\n",
    "# lista_foto=['eps', 'jpeg', 'jpg', 'pdf', 'png', 'ps', 'raw', 'rgba', 'svg', 'svgz', 'tif', 'tiff']\n",
    "# for cada in lista_foto:\n",
    "#     plt.savefig('/home/samuel/Imagens/radar.'+cada, format=cada)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
